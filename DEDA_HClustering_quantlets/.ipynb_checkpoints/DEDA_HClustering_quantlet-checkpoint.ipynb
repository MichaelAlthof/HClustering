{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install modules if they are not installed\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# additional set up\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=5, suppress=True) # suppress scientific float notation\n",
    "\n",
    "# constants and parameters\n",
    "DATA_PATH = './data/'\n",
    "IMG_PATH = './'\n",
    "\n",
    "# load data \n",
    "with open(f'{DATA_PATH}data_file_20181203.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame\n",
    "df = {'Name': np.zeros(len(data['quantlets'])), \n",
    "      'author_of_last_comm': np.zeros(len(data['quantlets'])),\n",
    "      'is_debuggable': np.zeros(len(data['quantlets'])), \n",
    "      'grade': np.zeros(len(data['quantlets'])),\n",
    "      'keywords': np.zeros(len(data['quantlets']))}\n",
    "\n",
    "df = pd.DataFrame(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the columns we need\n",
    "counter=0\n",
    "for c, i in enumerate(data['quantlets']):\n",
    "    print(i)\n",
    "    df.loc[c,'Name'] = i\n",
    "    df.loc[c,'author_of_first_comm'] = data['quantlets'][i]['commit_first']['commit']['author']['name']\n",
    "    df.loc[c,'author_of_last_comm'] = data['quantlets'][i]['commit_last']['commit']['author']['name']\n",
    "    df.loc[c,'is_debuggable'] = data['quantlets'][i]['is_debuggable']\n",
    "    try:\n",
    "        df.loc[c,'grade'] = data['quantlets'][i]['grade']\n",
    "        df.loc[c,'keywords'] = ' '.join(str(e) for e in set(data['quantlets'][i]['keyword_list']))\n",
    "    except:\n",
    "        df.loc[c,'grade'] = 'did not work'\n",
    "        df.loc[c,'keywords'] ='did not work'\n",
    "        counter+=1\n",
    "print(f'Could not load {counter} quantlets.')\n",
    "df = df[df['is_debuggable']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add HClustering\n",
    "df = df.append(pd.DataFrame({'Name' : 'DEDA_HClustering_image_example_km',\n",
    "                      'author_of_first_comm': 'Elizaveta Zinovyeva',\n",
    "                      'author_of_last_comm': 'Elizaveta Zinovyeva',\n",
    "                      'is_debuggable': True,\n",
    "                      'grade': 'NA',\n",
    "                      'keywords': 'Computer vision image segmentation k-means cluster analysis'}, index = [df.index.max()+1]), sort=False)\n",
    "\n",
    "df = df.append(pd.DataFrame({'Name' : 'DEDA_HClustering_quantlets',\n",
    "                      'author_of_first_comm': 'Elizaveta Zinovyeva',\n",
    "                      'author_of_last_comm': 'Elizaveta Zinovyeva',\n",
    "                      'is_debuggable': True,\n",
    "                      'grade': 'NA',\n",
    "                      'keywords': 'Quantlets hierarchical k-means cluster analysis'}, index = [df.index.max()+1]), sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df.keywords.values)\n",
    "train_X = tokenizer.texts_to_sequences(df.keywords.values, )\n",
    "train_X = [np.unique(i) for i in train_X]\n",
    "train_X = pad_sequences(train_X, maxlen=15, padding='post')\n",
    "#labels = [i.split('/')[1] for i in df.name]\n",
    "labels = []\n",
    "for i in df.Name:\n",
    "    temp = str(i).split('/')\n",
    "    if len(temp)==3:\n",
    "        labels.append(temp[1])\n",
    "    elif len(temp)==2:\n",
    "        labels.append(temp[0])\n",
    "    elif len(temp)==4:\n",
    "        labels.append(temp[2])\n",
    "    elif len(temp)==5:\n",
    "        labels.append(' '.join([temp[0],temp[3]]))\n",
    "    else:\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Quantlet Dendrogram\")  \n",
    "plt.xlabel('Quantlet')\n",
    "plt.ylabel('Distance')\n",
    "Z = shc.linkage(train_X[-10:], method='single', metric='hamming')\n",
    "dend = shc.dendrogram(Z, labels=labels[-10:], leaf_rotation=90) \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}dendr_small.png', transparent=True)\n",
    "d = pairwise_distances(train_X[-10:], metric='hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Quantlet Dendrogram\")  \n",
    "plt.xlabel('Quantlet')\n",
    "plt.ylabel('Distance')\n",
    "Z = shc.linkage(train_X, method='average', metric='cosine')\n",
    "dend = shc.dendrogram(Z, leaf_rotation=90, no_labels=True, count_sort=True)  \n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}dendr_full.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = fcluster(Z, 0.7, criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Quantlet Dendrogram (truncated)\")  \n",
    "plt.xlabel('Quantlet')\n",
    "plt.ylabel('Distance')\n",
    "Z = shc.linkage(train_X,  method='average', metric='cosine')\n",
    "dend = shc.dendrogram(Z, truncate_mode='lastp', p=25, labels=labels, leaf_rotation=90, count_sort=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{IMG_PATH}dendr_trunc.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z = shc.linkage(train_X, method='average', metric='cosine')\n",
    "max_d = 10\n",
    "#clusters = fcluster(Z, max_d, criterion='maxclust')\n",
    "cluster_labels = {}  \n",
    "for i in range(1, max_d+1):\n",
    "    df_ = pd.DataFrame(columns = ['word', 'count'])\n",
    "    df_['word'], df_['count'] = np.unique(train_X[clusters==i], return_counts=True)\n",
    "    df_ = df_.sort_values(by=['count'], ascending=False)\n",
    "    #print(df.head(20))\n",
    "    temp = []\n",
    "    for word in df_.word.values[1:10]:\n",
    "        if word != 0:\n",
    "            temp.append(reverse_word_map[word])\n",
    "    cluster_labels[i] = ' '.join(temp)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for plotting\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(train_X)\n",
    "X = pca.transform(train_X)\n",
    "\n",
    "for i in [1, 2, 3, 5, 7, 9, 10, 30, 100, 200, 500, len(df.keywords)]:\n",
    "    max_d = i\n",
    "    clusters = fcluster(Z, max_d, criterion='maxclust')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(X[:,0], X[:,1], c=clusters, cmap='prism')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.title(f'Scatter plot with clusters\\' amount = {i}')\n",
    "    filename=f'{IMG_PATH}/images/for_gif/step'+str(i)+'.png'\n",
    "    plt.savefig(filename, dpi=96, transparent=True)\n",
    "    plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit(train_X)\n",
    "X_t = tsne.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 5, 7, 9, 10, 30, 100, 200, 500, len(df.keywords)]:\n",
    "    max_d = i\n",
    "    clusters = fcluster(Z, max_d, criterion='maxclust')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(X_t[:,0], X_t[:,1], c=clusters, cmap='tab10')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.title(f'Scatter plot with clusters\\' amount = {i}')\n",
    "    filename=f'{IMG_PATH}/images/for_gif/TSNE_step'+str(i)+'.png'\n",
    "    plt.savefig(filename, dpi=96, transparent=True)\n",
    "    plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d=10\n",
    "clusters = fcluster(Z, max_d, criterion='maxclust')\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(1, max_d+1):\n",
    "    df_ = pd.DataFrame(columns = ['word', 'count'])\n",
    "    df_['word'], df_['count'] = np.unique(train_X[clusters==i], return_counts=True)\n",
    "    df_ = df_.sort_values(by=['count'], ascending=False)\n",
    "    #print(df.head(20))\n",
    "    temp = []\n",
    "    for word in df_.word.values[1:10]:\n",
    "        if word != 0:\n",
    "            temp.append(reverse_word_map[word])\n",
    "    cluster_labels[i] = ' '.join(temp)       \n",
    "    plt.scatter(X_t[clusters==i,0], X_t[clusters==i,1], label = cluster_labels[i])\n",
    "#plt.legend(loc = 'upper left', prop={'size': 10})\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(1.3, 0.8), prop={'size': 10})\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.title(f'Scatter plot with clusters\\' amount = {10}')\n",
    "filename=f'{IMG_PATH}TSNE_10_clusters.png'\n",
    "plt.savefig(filename, dpi=96, transparent=True)\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d=10\n",
    "clusters = fcluster(Z, max_d, criterion='maxclust')\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(1, max_d+1):\n",
    "    df_ = pd.DataFrame(columns = ['word', 'count'])\n",
    "    df_['word'], df_['count'] = np.unique(train_X[clusters==i], return_counts=True)\n",
    "    df_ = df_.sort_values(by=['count'], ascending=False)\n",
    "    #print(df.head(20))\n",
    "    temp = []\n",
    "    for word in df_.word.values[1:10]:\n",
    "        if word != 0:\n",
    "            temp.append(reverse_word_map[word])\n",
    "    cluster_labels[i] = ' '.join(temp)       \n",
    "    plt.scatter(X_t[clusters==i,0], X_t[clusters==i,1], label = cluster_labels[i])\n",
    "#plt.legend(loc = 'upper left', prop={'size': 10})\n",
    "#plt.legend(loc='upper center', bbox_to_anchor=(1.3, 0.8), prop={'size': 10})\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.title(f'Scatter plot with clusters\\' amount = {10}')\n",
    "filename=f'{IMG_PATH}TSNE_10_clusters.png'\n",
    "plt.savefig(filename, dpi=96, transparent=True)\n",
    "plt.gca()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
